---
layout: post
title:  "Linux memory manager"
date: 2020-08-31 18:00:00 +0800
categories: jekyll update
---

1. 页框管理
2. 内存区管理
3. 非连续内存区管理

页框管理和内存区管理介绍对连续物理内存区处理。
非连续内存区管理介绍非连续物理内存区的处理。


## 1. 页框管理

### 1.1 页描述符

内核必须记录每个页框当前的状态。每个描述符长度32字节。
内核需要区分哪些页框包含的数据是属于进程的或是属于内核的页。内核还需要确定页框是否空闲。
包含用户态进程数据，软件高速缓存数据、动态分配内核数据结构、设备驱动程序缓冲数据、内核模块等数据的页框是不空闲的。

### 1.2 非一致内存访问(NUMA)

NUMA(Non-uniform Memory Access)
给定CPU对不同内存单元的访问时间可能不一样。系统物理内存被划分为几个节点(node)。在一个单独的节点内，任一给定CPU访问
页面所需的时间都是相同的。然而，不同的CPU，这个时间可能就不同。对每个CPU而言，内核都试图把耗时节点的访问次数减少到
最少，这就小心地选择CPU最常引用的内核数据结构的存放位置。

每个节点(node)的物理内存又可以分为几个管理区(zone)

### 1.3 内存管理区(zone)

计算机体系结构有硬件的制约，限制了页框使用方式。尤其Linux内核必须处理80x86体系结构的两种硬件约束:

ISA总线的直接内存存取(DMA)处理器有一个严格的限制，它们只能对RAM前16MB寻址。

具有大容量RAM的现代32位计算机中，CPU不能直接访问所有物理内存，因为线性地址空间太小。

为了应对这两种限制，Linux 2.6把每个内存节点的物理内存划分为3个管理区(zone)。

ZONE_DMA 低于16MB的内存页框

ZONE_NORMAL 高于16MB且低于896MB的内存页框

ZONE_HIGHMEM 大于等于896MB的内存页框

### 1.4 保留的页框

请求内存，如果有足够的空闲内存可用，请求就会立即满足。

否则，必须回收一些内存，并且将发出请求的内核控制路径阻塞，直到有内存释放出。

特定一些内核控制路径不能被阻塞，比如处理中断，执行临界区代码。这种情况下，一般内核控制路径应当产生原子内存分配请求。
原子请求从不被阻塞，如果没有足够空闲页，就是分配失败。为了减少失败，内核为原子内存分配请求保留一个页框池，只有在内存
不足时才使用。

### 1.5 分区页框分配器(zoned page frame allocator)

![Components of the zoned page frame allocator](https://williammuji.github.io/images/zoned-page-frame-allocator.png)


主要处理对连续页框组的内存分配请求。每个管理区内，页框使用“伙伴系统算法”(buddy)来处理。为了更好的系统性能，一小部分页框
保留在高速缓存中用于快速地满足对单个页框的分配请求。

### 1.6 高端内存页框的内核映射

896MB以上的高端内存页框并不映射在内核线性地址空间的第4个GB，因此，内核不能直接访问它们。64位硬件平台上不存在这个问题，
因为可使用的线性地址空间远大于能安装的RAM大小，这些体系结构的ZONE_HIGHMEM管理区是空的。但是32位平台上，如80x86体系结构，
Linux设计者不得不使用某种方法来允许内核使用所有可使用的RAM，达到PAE所支持的64GB。

高端内存页框分配不返回第一个被分配页框的线性地址，而返回第一个被分配页框的页描述符的线性地址

没有线性地址的高端内存中的页框不能被内核访问，因此，内核线性地址空间最后128MB中的一部分专门用于高端内存页框，这种映射
是暂时的，通过重复使用线性地址，使得整个高端内存能够在不同的时间被访问。

内核采用三种不同机制将页框映射到高端内存：永久内核映射、临时内核映射、非连续内存分配。


### 1.7 伙伴系统算法(The Buddy System Algorithm)

内核为分配一组连续的页框而建立一种健壮、高效的分配策略。为此必须解决外碎片(external fragmentation)。频繁地请求和释放不同大小
的一组连续页框，必然导致在已分配页框的块内分散了许多小块的空闲页框。这样时间久了，即使有足够的空闲页框可以满足请求，但要分配
一个大块的连续页框可能无法满足。

两种避免外部碎片办法：

1、利用分页单元把一组非连续的空闲页框映射到连续的线性地址空间。

2、记录现存空闲连续页框块，尽量避免为满足小块的请求而分割大的空闲块。

内核首选第二种方法，Linux采用著名的伙伴系统(buddy system)算法来解决外碎片问题。

把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1,2,4,8,16,32,64,128,256,512和1024个连续的页框。对1024个页框的最大请求
对应着4MB大小的连续RAM块。每个块的第一个页框的物理地址是该块大小的整数倍。

举例：假设要请求一个256个页框的块(1MB)。算法先在256个页框的链表中检查是否有一个空闲块。如果没有这样的块，算法会查找下一个更大的页块。
也就是，在512个页框的链表中找一个空闲块。如果存在这样的块，内核就把256的页框分成两等份，一半用作满足请求，另一半插入到256个页框的
链表中。如果在512个页框的块链表中也没有找到空闲块，就继续找更大的块--1024个页框的块。如果这样的块存在，内核把1024个页框的256个页框
用作请求，然后从剩余的768个页框拿处512个插入到512个页框的链表中，再把最后的256个插入到256个页框的链表中。如果1024个页框的链表还是空
的，算法就放弃并发出错信号。

以上过程的逆过程就是页框快的释放过程，也就是该算法名字的由来。内核试图把大小为b的一对空闲伙伴块合并为一个大小为2b的单独块。满足以下
条件的两个块称为伙伴：

1、两个块具有相同的大小，记作b

2、它们的物理地址是连续的

3、第一块的第一个页框的物理地址是2*b*pow(2,12)的倍数

算法是迭代的，如果它成功合并所释放的块，它会试图合并2b的块，以再次试图形成更大的块。


## 2. 内存区(memory area)管理

主要关注具有连续的物理地址和任意长度的内存单元序列。伙伴系统算法采用页框为基本内存区，适合大块内存的请求，如果存放很少的字节而给它分配
一个整页框，比较浪费。所以引入一种新的数据结构来描述同一页框中如何分配小内存区。但这样会引起内碎片(internal fragmentation)。内碎片产生
主要是由于请求内存的大小与分配给它的大小不匹配造成。

Linux系统早期采用按几何分布的内存区大小，它取决于2的幂，大小从32到131072字节，不管大小多少，都可保证碎片小于50%。伙伴系统调用既为了获得
存放新内存区所需要的额外页框，也为了释放不在包含在内存区的页框。用一个动态链表来记录每个页框所包含的空闲内存区。

### 2.1 Slab分配器

buddy alogrithm对运行内存区分配算法没有显著的效率，有一种更好的算法源自slab分配器模式，它基于下列前提：

1、存放数据类型可以影响内存区的分配方式。它把内存区看做对象(object)，对象由一组数据结构和几个构造、析构函数组成，为了避免重复初始化对象，slab
分配器并不丢弃已分配对象，而是释放但把它们保存在内存中。当以后要请求新的对象时，就可以从内存中获取而不用重新初始化。

2、内核函数倾向于反复请求同一类型的内存区。比如内核创建一个新进程，它就要为一些固定大小的表（进程描述符、打开文件对象等）分配内存区，进程结束时，
包含这些表的内存区还可以被重新使用。而进程的创建和撤销非常频繁，若没有slab分配器，内核把时间浪费在反复分配和回收那些包含同一内存区的页框上。slab
分配器把那些页框保存在高速缓存中并很快地重新使用它们。

3、对内存区的请求可以根绝它们发生的频率来分类。对于预期频繁请求一个特定大小的内存区而言，可以通过创建一组具有适当大小的专用对象来高效地处理，由此
避免内碎片的产生。另一种情况，对于很少遇到的内存区大小，可以通过基于一系列几何分布大小（2的幂次方）的对象的分配模式来处理。

slab分配器把对象分组放进cache，每个cache都是同种类型对象的一种store。

![The slab allocator components](https://williammuji.github.io/images/slab-alloactor-components.jpg)

### 2.2 Cache & Slab Descriptors

![Relationship between cache and slab descriptors](https://williammuji.github.io/images/cache-slab-descriptor.png)

![Relationship between slab and object descriptors](https://williammuji.github.io/images/slab-object-descriptors.jpg)

### 2.3 General and Specific Caches

General caches are used only by the slab allocator for its own purposes, while specific caches are used by the remaining parts of the kernel.

普通缓存

1、kmem_cache，包含由内核使用的其余高速缓存的缓存描述符。

2、包含用作普通用途的内存区。一个叫做malloc_sizes的表，分别只想26个缓存描述符，对于13种大小(32-131072)都有两个高速缓存：一个适用于ISA DMA分配，
另一个适用于常规分配。

系统初始化期间调用kmem_cache_init和kmem_cache_sizes_init来建立普通缓存。

专用缓存由kmem_cache_create函数创建。普通和专用缓存都可以在运行期间通过/proc/slabinfo文件得到，它指明了每个缓存中空闲对象的个数和已分配对象的
个数。

### 2.4 Aligning Objects in Memory

如果对象大小小于cache line的一半，就在RAM中根据L1_CACHE_BYTES的倍数来对齐对象

否则，对象大小就是L1_CACHE_BYTES的因子取整，这样可以保证小对象不会横跨两个cache line。

slab分配器通过空间换时间，人为增加对象大小来获得更好的缓存性能，但也引起额外的碎片。

### 2.5 Slab Coloring

同一硬件cache line可以映射RAM中很多不同的块。相同大小的对象倾向于存放在缓存内相同的偏移量处。不同slab内具有相同偏移量的对象最终很可能映射
到同一cache line中。高速缓存硬件可能因此花费内存周期在同一高速缓存行与RAM内存单元之间来回传送两个对象，而其他的高速缓存行并未充分使用。
slab分配器通过slab coloring的策略，尽量降低高速缓存的这种行为，它把叫做color的不同随机数分配给slab。


### 2.6 General Purpose Objects

如果对存储区的请求不频繁，就用一组普通缓cache处理，普通cache中的对象具有几何分布大小，范围为32-131072字节。调用kmalloc函数可以得到这种类型
的对象。

### 2.7 Memory Pools

内存池是Linux2.6一个新特性，它允许内核部分，如块设备子系统，在内存不足的紧急情况下分配一些动态内存来使用。
内存池是动态存储的储备，只能被特定的内核部分使用，如果动态内存变得极其稀有以至于所有普通内存分配请求都将失败的话，那么作为最后的解决手段，内核
部分就能调用特定的内存池函数提取储备所得的内存。

一个内存池常常叠加在slab分配器上，也就是说，它被用来保存slab对象的储备，内存池也能被用来分配任何一种类型的动态内存，从整个页框到使用kmalloc分配
的小内存区。


## 3. 非连续内存区管理

一般把内存区映射到一组连续的页框是最好的选择，这样会充分利用高速缓存并获得较低的平均访问时间。如果对内存区请求不是很频繁，那么通过连续线性
地址访问非连续页框比较有意义。这种模式优点避免了外碎片，缺点是必须打乱内核页表。Linux几个方面使用非连续内存区，为活动交换区分配数据结构，为
模块分配空间，给某些I/O驱动程序分配缓冲区。

1、内存区开始部分包含的是对前896MB RAM进行映射的线性地址，直接映射的物理内存末尾所对应的线性地址保存在high_memory变量中

2、内存区结尾部分包含的是固定映射的线性地址

3、从PKMAP_BASE开始，我们查找用于高端内存页框的永久内核映射的线性地址

4、物理内存映射末尾与第一个内存区之间插入8MB的安全区，目的是为了捕获对内存的越界访问。同样，插入其他4KB大小的安全区来隔离非连续内存区

为非连续内存区保留的线性地址空间的其实地址由VMALLOC_START宏定义，而末尾地址由VMALLOC_END宏定义。

![The linear address interval starting from PAGE_OFFSET](https://williammuji.github.io/images/page-offset-linear-address.jpg)
